---
title: "RandomForestAssignment"
author: "Gregory Blane"
date: "2/11/2021"
output:
  word_document: default
  html_document: default
---
```{r FALSE}
library(tidyverse)
library(tidymodels)
library(caret)
library(gridExtra)
library(vip)
library(ranger)
library(skimr)
```

```{r}
drug =read_csv("drug_data-1.csv")
```

```{r}
names(drug) =c("ID", "Age", "Gender", "Education", "Country", "Ethnicity","Nscore", "Escore", "Oscore", "Ascore", "Cscore", "Impulsive","SS", "Alcohol", "Amphet", "Amyl", "Benzos", "Caff", "Cannabis","Choc", "Coke", "Crack", "Ecstasy", "Heroin", "Ketamine", "Legalh","LSD", "Meth", "Mushrooms", "Nicotine", "Semer", "VSA")

#str(drug)
```

```{r}
drug[drug=="CL0"] = "No"
drug[drug=="CL1"] = "No"
drug[drug=="CL2"] = "Yes"
drug[drug=="CL3"] = "Yes"
drug[drug=="CL4"] = "Yes"
drug[drug=="CL5"] = "Yes"
drug[drug=="CL6"] = "Yes"
```

```{r}
drug_clean = drug%>% mutate_at(vars(Age:Ethnicity),funs(as_factor))%>%mutate(Age =factor(Age, labels =c("18_24", "25_34", "35_44","45_54", "55_64", "65_")))%>%mutate(Gender =factor(Gender, labels =c("Male", "Female")))%>%mutate(Education =factor(Education, labels =c("Under16", "At16", "At17", "At18", "SomeCollege","ProfessionalCert", "Bachelors", "Masters", "Doctorate")))%>%mutate(Country =factor(Country,labels =c("USA", "NewZealand", "Other", "Australia","Ireland","Canada","UK")))%>%mutate(Ethnicity =factor(Ethnicity,labels =c("Black", "Asian", "White", "White/Black", "Other","White/Asian", "Black/Asian")))%>%
  mutate_at(vars(Alcohol:VSA),funs(as_factor))%>%select(-ID)
```

```{r}
#str(drug_clean)
```

```{r}
names(drug_clean)
drug_clean = drug_clean %>% 
  select(!(Alcohol:Mushrooms))%>% 
  select(!(Semer:VSA))
```


#### There is no missing data. 


```{r}
skim(drug_clean)
```


```{r}
set.seed(1234) 
drugC_split = initial_split(drug_clean, prop = 0.7, strata = Nicotine) 
train = training(drugC_split)
test = testing(drugC_split)
```


#### The relationship between  individuals with the age range of 65 and older do not use nicotine. Females appears to use less nicotine than males. People with docorates are not likely to use nicotine. The united kingdom appears to less nicotine compared to other countries. 


```{r}
p1 = ggplot(train, aes(x = Age, fill = Nicotine)) + geom_bar(position = "fill")
p2 = ggplot(train, aes(x = Gender, fill = Nicotine)) + geom_bar(position = "fill")
p3 = ggplot(train, aes(x = Education, fill = Nicotine)) + geom_bar(position = "fill")
p4 = ggplot(train, aes(x = Country, fill = Nicotine)) + geom_bar(position = "fill")
grid.arrange(p1,p2,p3,p4)
```


####  The relationship between Blacks and Asians doesn't appear to have any difference. People with Nscore seem to use nicotine more. For Escore, there really isn't a difference. People with Oscore tends to use nicotine more.


```{r}
p1 = ggplot(train, aes(x = Ethnicity, fill = Nicotine)) + geom_bar(position = "fill")
p2 = ggplot(train, aes(x = Nicotine, y = Nscore )) + geom_boxplot()
p3 = ggplot(train, aes(x = Nicotine, y = Escore)) + geom_boxplot()
p4 = ggplot(train, aes(x = Nicotine, y = Oscore)) + geom_boxplot()
grid.arrange(p1,p2,p3,p4, ncol = 2)
```


#### Ascore doesn't have much of a difference. People with C score tends not to use nicotine as much. Those who are impulsive seems to use nicotine more. People with SS uses nicotine more. 


```{r}
p1 = ggplot(train, aes(x = Nicotine, y = Ascore)) + geom_boxplot()
p2 = ggplot(train, aes(x = Nicotine, y = Cscore)) + geom_boxplot()
p3 = ggplot(train, aes(x = Nicotine, y = Impulsive)) + geom_boxplot()
p4 = ggplot(train, aes(x = Nicotine, y = SS)) + geom_boxplot()
grid.arrange(p1,p2,p3,p4, ncol = 2)
```

```{r}
set.seed(123)
rf_folds = vfold_cv(train, v = 5)
```

```{r}
drug_recipe = recipe(Nicotine ~., train) %>%
  step_dummy(all_nominal(), -all_outcomes())

rf_model = rand_forest(mtry = tune(), min_n = tune(), trees = 100) %>%
  set_engine("ranger", importance = "permutation") %>% 
  set_mode("classification")

drug_wflow = 
  workflow() %>% 
  add_model(rf_model) %>% 
  add_recipe(drug_recipe)

set.seed(123)
rf_res = tune_grid(
  drug_wflow,
  resamples = rf_folds,
  grid = 20 
)
```

```{r}
rf_res %>%
  collect_metrics() %>%
  filter(.metric == "accuracy") %>%
  select(mean, min_n, mtry) %>%
  pivot_longer(min_n:mtry,
    values_to = "value",
    names_to = "parameter"
  ) %>%
  ggplot(aes(value, mean, color = parameter)) +
  geom_point(show.legend = FALSE) +
  facet_wrap(~parameter, scales = "free_x") +
  labs(x = NULL, y = "Accuracy")
```


#### As min_n increases, accuracy slighly increases. As mntry increases, the accuracy decreases. 


```{r}
drug_recipe = recipe(Nicotine ~., train) %>%
  step_dummy(all_nominal(), -all_outcomes())

rf_model = rand_forest(mtry = tune(), min_n = tune(), trees = 100) %>% 
  set_engine("ranger", importance = "permutation") %>% 
  set_mode("classification")

drug_wflow = 
  workflow() %>% 
  add_model(rf_model) %>% 
  add_recipe(drug_recipe)

rf_grid = grid_regular(
  mtry(range = c(2, 8)),
  min_n(range = c(5, 20)),  
  levels = 10
)


set.seed(123)
rf_res_tuned = tune_grid(
  drug_wflow,
  resamples = rf_folds,
  grid = rf_grid 
)
```

```{r}
rf_res_tuned %>%
  collect_metrics() %>%
  filter(.metric == "accuracy") %>%
  select(mean, min_n, mtry) %>%
  pivot_longer(min_n:mtry,
    values_to = "value",
    names_to = "parameter"
  ) %>%
  ggplot(aes(value, mean, color = parameter)) +
  geom_point(show.legend = FALSE) +
  facet_wrap(~parameter, scales = "free_x") +
  labs(x = NULL, y = "Accuracy")
```



```{r}
best_rf = select_best(rf_res_tuned, "accuracy")

final_rf = finalize_workflow(
  drug_wflow,
  best_rf
)

final_rf
```

```{r}
final_rf_fit = fit(final_rf, train)
```


#### The important variable are SS, Country_UK, Oscore, and Gender_female.


```{r}
final_rf_fit %>% pull_workflow_fit() %>% vip(geom = "point")
```

--- 
Training predictions
---

```{r}
trainpredrf = predict(final_rf_fit, train)
```


#### The accuracy of the training set is 84%.


```{r}
confusionMatrix(trainpredrf$.pred_class, train$Nicotine, 
                positive = "Yes")
```


#### The prediction on the testing set is 71%. The perfromance between the two prediction sets are inconsistent. 


```{r}
testpredrf = predict(final_rf_fit, test)
confusionMatrix(testpredrf$.pred_class, test$Nicotine, 
                positive = "Yes")
```



####  A random forest model can be used to help MetLife predict customers patterns, behaviors, and choices to better provide services that correlate to their current situation. At Metlife as a junior database engineer, I shadowed a few data scientists on how they used analytics to help predict insurance turnover, or underwriting to establish pricing for insurable risk. The only concerns I have is the time it takes to run these models on big data or large data sets.




